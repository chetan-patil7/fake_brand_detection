{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAc73wrFixbq"
   },
   "source": [
    "## **Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SB3WmqTQWboq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_images = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.load('val_data.npy')\n",
    "test_images = np.load('test_data.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "test_labels = np.load('test_labels.npy')\n",
    "val_labels = np.load('val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1T3XSPuOXJKw"
   },
   "outputs": [],
   "source": [
    "# flatten the images to use them as features\n",
    "train_features = train_images.reshape(train_images.shape[0], -1)\n",
    "val_features = val_images.reshape(val_images.shape[0], -1)\n",
    "test_features = test_images.reshape(test_images.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "JXtMiCvkaOJs",
    "outputId": "2b45a0a6-7088-46c2-ae69-6e7a4a5e504f"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.79 GiB for an array with shape (7753, 65536) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# train the SVM model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m svm\u001b[38;5;241m.\u001b[39mfit(train_features, train_labels)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:238\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# var = E[X^2] - E[X]^2 if sparse\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m         X_var \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m.\u001b[39mmultiply(X))\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m (X\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mvar()\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m X_var) \u001b[38;5;28;01mif\u001b[39;00m X_var \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:236\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    231\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean \u001b[38;5;241m/\u001b[39m rcount\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m x \u001b[38;5;241m=\u001b[39m asanyarray(arr \u001b[38;5;241m-\u001b[39m arrmean)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m    239\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, x, out\u001b[38;5;241m=\u001b[39mx)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.79 GiB for an array with shape (7753, 65536) and data type float64"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# train the SVM model\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x76g2ZpiaTz_",
    "outputId": "320d8a97-a811-445b-f3ab-ce9e1ae4bb66"
   },
   "outputs": [],
   "source": [
    "# evaluate the model on validation set\n",
    "val_preds = svm.predict(val_features)\n",
    "val_acc = accuracy_score(val_labels, val_preds)\n",
    "print(\"Validation accuracy:\", val_acc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "test_preds = svm.predict(test_features)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GmvVGhqhDW8",
    "outputId": "a0a56b78-518d-46df-fe45-7d91b78f309a"
   },
   "outputs": [],
   "source": [
    "# calculate precision, recall, and F1 score for the predicted labels\n",
    "val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
    "val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
    "val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "\n",
    "# print the results\n",
    "print(\"Validation precision:\", val_precision)\n",
    "print(\"Validation recall:\", val_recall)\n",
    "print(\"Validation F1 score:\", val_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U861rfVMhgEN"
   },
   "source": [
    "The validation precision of 0.8673974604531407 and recall of 0.8757738340899711 means that the precision and recall are around 0.87-0.88%, which indicates that the model is able to identify negative cases (i.e., original images) with a high degree of accuracy. The F1 score is around 0.87, which suggests that the model is able to balance precision and recall reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06GEZY4qhGMx",
    "outputId": "2fdf760b-f380-4ef9-aab2-630065984fc7"
   },
   "outputs": [],
   "source": [
    "test_precision = precision_score(test_labels, test_preds, average='weighted')\n",
    "test_recall = recall_score(test_labels, test_preds, average='weighted')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='weighted')\n",
    "print(\"Test precision:\", test_precision)\n",
    "print(\"Test recall:\", test_recall)\n",
    "print(\"Test F1 score:\", test_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAwJ1XTHhe2h"
   },
   "source": [
    "test precision of 0.8685877164107546, which means that 87% of the predictions made by the model for the positive class were correct. The test recall is 0.8774246801485761, which means that 86% of the actual negative examples in the test set were correctly identified by the model. F1 score is 0.87, which indicates that the model has a good balance of precision and recall and is performing well overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jlEAngFhI09",
    "outputId": "9fe6da38-f66f-43a0-baea-a34dbc31bb38"
   },
   "outputs": [],
   "source": [
    "# here we calculate the confusion matrix of the model's predictions on the test set.\n",
    "cm=confusion_matrix(test_labels,test_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "O-JJY9cFhLhb",
    "outputId": "a66598ee-4b4b-4371-add5-0e1c4e814f81"
   },
   "outputs": [],
   "source": [
    "# visual representation of confusion matrix of the model's predictions.\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks([0, 1], labels=[\"Negative\", \"Positive\"])\n",
    "plt.yticks([0, 1], labels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_4UaKVXhY1-"
   },
   "source": [
    "In this case, there were 1912 true negative predictions, 102 false positive predictions, 195 false negative predictions and 214 true positive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "3jxJkGv9hNjk",
    "outputId": "d60ec0c5-808d-4c0c-b08d-706b16a9de6b"
   },
   "outputs": [],
   "source": [
    "precision, recall, f1_score, support = precision_recall_fscore_support(test_labels, test_preds)\n",
    "class_names = ['Original', 'Fake']\n",
    "x = np.arange(len(class_names))\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(12, 5))\n",
    "rects1 = ax[0].bar(x, precision, width=0.4, align='center', label='Precision', color=['tab:blue', 'tab:orange'])\n",
    "rects2 = ax[1].bar(x, recall, width=0.4, align='center', label='Recall', color=['tab:blue', 'tab:orange'])\n",
    "rects3 = ax[2].bar(x, f1_score, width=0.4, align='center', label='F1-score', color=['tab:blue', 'tab:orange'])\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.set_xticks(x)\n",
    "    axi.set_xticklabels(class_names)\n",
    "    axi.set_ylabel('Score')\n",
    "    axi.set_title(['Precision', 'Recall', 'F1-score'][i])\n",
    "    axi.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5Lxm-L-hTMt"
   },
   "source": [
    "The precision, recall and F1 score for original class is higher as compared to fake class."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
